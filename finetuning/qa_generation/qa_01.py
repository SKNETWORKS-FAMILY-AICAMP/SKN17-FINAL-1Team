import json
import re
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI()

# --------------------------------------------------
# JSON ì•ˆì „ íŒŒì„œ
# --------------------------------------------------
def safe_load_json(content: str):
    content = content.strip()

    # ì½”ë“œë¸”ë¡ ì œê±°
    content = re.sub(r"^```json|^```", "", content)
    content = re.sub(r"```$", "", content)

    # stray comma ì œê±°
    content = re.sub(r",\s*]", "]", content)
    content = re.sub(r",\s*}", "}", content)

    # ê´„í˜¸ ë¶ˆì¼ì¹˜ ìë™ ë³´ì •
    if content.count("[") > content.count("]"):
        content += "]"
    if content.count("{") > content.count("}"):
        content += "}" * (content.count("{") - content.count("}"))

    return json.loads(content)


def generate_batch(batch_size: int):
    """100ê°œ ë‹¨ìœ„ë¡œ ì•ˆì •ì ìœ¼ë¡œ ìƒì„±"""
    
    system_prompt = "You ONLY output valid JSON array. No explanation, no commentary."

    prompt = f"""
        í—¤ì–´ìŠ¤íƒ€ì¼ ìƒë‹´ ì±—ë´‡ 'HairAllYou'ì˜ ì¼ë°˜ ì§ˆì˜ ëŒ€ì‘ ë°ì´í„°ì…‹ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

        ì´ {batch_size}ê°œì˜ í•­ëª©.
        ê° í•­ëª©ì€ JSON ë°°ì—´ ìš”ì†Œë¡œ ì¶œë ¥í•˜ì„¸ìš”.

        í˜•ì‹:
        {{
          "type": "...",
          "user": "...",
          "assistant": "..."
        }}

        ìƒì„± ê·œì¹™ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

        [ì¹´í…Œê³ ë¦¬ 1: greeting]
        user ì˜ˆ: ì•ˆë…•, í•˜ì´, ë°˜ê°€ì›Œ
        assistant:
        "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í—¤ì–´ìŠ¤íƒ€ì¼ê³¼ ê´€ë ¨ëœ ìƒë‹´ì„ ë„ì™€ì£¼ëŠ” HairAllYou ì±—ë´‡ğŸ¤–ì…ë‹ˆë‹¤. ì–´ë–¤ ê²ƒì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

        [ì¹´í…Œê³ ë¦¬ 2: irrelevant]
        user ì˜ˆ: ë‚ ì”¨, ì£¼ì‹, ìš”ë¦¬, ì½”ë”© ë“±
        assistant:
        "ì €ëŠ” í—¤ì–´ìŠ¤íƒ€ì¼ê³¼ ê´€ë ¨ëœ ìƒë‹´ì„ ë„ì™€ì£¼ëŠ” HairAllYou ì±—ë´‡ì…ë‹ˆë‹¤. í—¤ì–´ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ê²ƒë§Œ ë‹µë³€í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”ğŸ¥²"

        [ì¹´í…Œê³ ë¦¬ 3: function_info]
        assistant:
        "ì €ëŠ” í—¤ì–´ìŠ¤íƒ€ì¼ì— ê´€ë ¨ëœ ìƒë‹´ì„ ë„ì™€ë“œë¦¬ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤ğŸ˜Š
        1. í—¤ì–´ìŠ¤íƒ€ì¼ ì •ë³´
        2. ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ ì¶”ì²œ
        3. ì´ë¯¸ì§€ ë¶„ì„
        4. ì´ë¯¸ì§€ ìƒì„±
        ë¬´ì—‡ë¶€í„° ë„ì™€ë“œë¦´ê¹Œìš”?ğŸ˜Š"

        [ì¹´í…Œê³ ë¦¬ 4: hair_change]
        assistant:
        "í—¤ì–´ìŠ¤íƒ€ì¼ì„ ë³€ê²½í•˜ê³  ì‹¶ìœ¼ì‹œêµ°ìš”!ğŸ˜Š ì–´ìš¸ë¦´ ìŠ¤íƒ€ì¼ ì¶”ì²œì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!
        - ì„±ë³„
        - ì–¼êµ´í˜•
        - í¼ìŠ¤ë„ì»¬ëŸ¬
        ì›í•˜ëŠ” ê¸¸ì´ë‚˜ ëŠë‚Œë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”!"

        [ì¹´í…Œê³ ë¦¬ 5: hair_dissatisfaction]
        assistant:
        "í—¤ì–´ìŠ¤íƒ€ì¼ì´ ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ì‹œë‹¤ë‹ˆ ì†ìƒí•˜ì‹œê² ì–´ìš”ğŸ¥² í•˜ì§€ë§Œ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”! ë‹¤ìŒë²ˆ ì‹¤íŒ¨í•˜ì§€ ì•Šë„ë¡ íŒ ì•Œë ¤ë“œë¦´ê¹Œìš”?"

        [ì¹´í…Œê³ ë¦¬ 6: salon_tips]
        assistant:
        "ë¯¸ìš©ì‹¤ íŒì„ ì•Œë ¤ë“œë¦´ê²Œìš”! ì‚¬ì§„ ì¤€ë¹„, ëª¨ë°œ ìƒíƒœ ê³µìœ , ìš”êµ¬ì‚¬í•­ êµ¬ì²´í™”, ì¤‘ê°„ ì†Œí†µ, ê´€ë¦¬ë²• ì§ˆë¬¸í•˜ê¸° ë“±ì´ ìˆì–´ìš”ğŸ˜Š"

        [ì¹´í…Œê³ ë¦¬ 7: shop_restriction]
        assistant:
        "ì£„ì†¡í•˜ì§€ë§Œ íŠ¹ì • ë¯¸ìš©ì‹¤ì´ë‚˜ ë””ìì´ë„ˆ ì¶”ì²œì€ ì–´ë ¤ì›Œìš”ğŸ¥² í—¤ì–´ìŠ¤íƒ€ì¼ ì •ë³´ëŠ” ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ê²Œìš”!ğŸ˜Š"
    """

    for _ in range(3):
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,
        )
        content = response.choices[0].message.content.strip()

        try:
            return safe_load_json(content)
        except:
            continue

    raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨(3íšŒ).")


def generate_greeting_and_irrelevant_samples(num_samples: int = 100):
    results = []
    batch_size = 20

    while len(results) < num_samples:
        needed = min(batch_size, num_samples - len(results))
        batch = generate_batch(needed)
        results.extend(batch)

    return results[:num_samples]


def convert_to_training_format(samples: list) -> list:
    training_data = []
    for sample in samples:
        training_data.append({
            "messages": [
                {"role": "system", "content": ""},
                {"role": "user", "content": sample["user"]},
                {"role": "assistant", "content": sample["assistant"]},
            ]
        })
    return training_data


def save_to_jsonl(data: list, filename: str):
    with open(filename, "w", encoding="utf-8") as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    print(f"ì €ì¥ ì™„ë£Œ: {filename} ({len(data)}ê°œ)")


def get_data(num_samples: int = 100, output_file: str = "greeting_irrelevant.jsonl"):
    print(f"{num_samples}ê°œ ìƒì„± ì‹œì‘...(gpt-4o-mini)")

    raw = generate_greeting_and_irrelevant_samples(num_samples)
    print(f"ìƒì„± ì™„ë£Œ: {len(raw)}ê°œ")

    training = convert_to_training_format(raw)
    save_to_jsonl(training, output_file)

    return training


if __name__ == "__main__":
    get_data(num_samples=100, output_file="finetuning/samples/greeting_irrelevant.jsonl")
